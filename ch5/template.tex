\documentclass[twoside]{article}
\setlength{\oddsidemargin}{0 in}
\setlength{\evensidemargin}{0 in}
\setlength{\topmargin}{-0.6 in}
\setlength{\textwidth}{6.5 in}
\setlength{\textheight}{8.5 in}
\setlength{\headsep}{0.75 in}
\setlength{\parindent}{0 in}
\setlength{\parskip}{0.1 in}

%
% ADD PACKAGES here:
%
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amsfonts,amssymb,graphicx,mathtools}
\usepackage[document]{ragged2e}
\usepackage[Euler]{upgreek}
\usepackage{amsthm}

\usepackage[backend=biber]{biblatex}
\addbibresource{ref.bib}

\graphicspath{{./rsc/}{./rsc/pdf/}{./rsc/svg/}}

% Define mathbfit
\DeclareMathAlphabet{\mathbfit}{OML}{cmm}{b}{it}
\DeclareMathAlphabet{\mathbfsf}{\encodingdefault}{\sfdefault}{bx}{n}

% Define operators
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\minimize}{Minimize}
\DeclareMathOperator*{\maximize}{Maximize}

\DeclareMathOperator*{\dotcup}{\dot{\cup}}

% Define textbfit
\makeatletter
\DeclareRobustCommand\bfseriesitshape{
  \not@math@alphabet\itshapebfseries\relax
  \fontseries\bfdefault
  \fontshape\itdefault
  \selectfont
}
\makeatother
\DeclareTextFontCommand{\textbfit}{\bfseriesitshape}

\expandafter\def\expandafter\normalsize\expandafter{%
    \normalsize
    \setlength\abovedisplayskip{15pt}
    \setlength\belowdisplayskip{15pt}
    \setlength\abovedisplayshortskip{15pt}
    \setlength\belowdisplayshortskip{15pt}
}

%
% The following commands set up the lecnum (lecture number)
% counter and make various numbering schemes work relative
% to the lecture number.
%
\newcounter{lecnum}
\renewcommand{\thepage}{\thelecnum-\arabic{page}}
\renewcommand{\thesection}{\thelecnum.\arabic{section}}
\renewcommand{\theequation}{\thelecnum.\arabic{equation}}
\renewcommand{\thefigure}{\thelecnum.\arabic{figure}}
\renewcommand{\thetable}{\thelecnum.\arabic{table}}

%
% Narrower margin
%
\def\changemargin#1#2{\list{}{\rightmargin#2\leftmargin#1}\item[]}
\let\endchangemargin=\endlist
%
% The following macro is used to generate the header.
%
\newcommand{\lecture}[4]{
  \pagestyle{myheadings}
  \thispagestyle{plain}
  \newpage
  \setcounter{lecnum}{#1}
  \setcounter{page}{1}
  \noindent
  \begin{center}
    \framebox{
      \vbox{
        \vspace{2mm}
        \hbox to 6.28in { {\bf MAT2013: Probability and Statistics~\cite{IPSUR-2010}~\cite{RP-Babatunde-2009} \hfill Spring 2017} }
        \vspace{4mm}
        \hbox to 6.28in { {\Large \hfill Lecture #1: #2  \hfill} }
        \vspace{2mm}
        \hbox to 6.28in { {\it Lecturer: #3 \hfill Scribes: #4\/} }
        \vspace{2mm}
      }
    }
  \end{center}
  \markboth{Lecture #1: #2}{Lecture #1: #2}
  {\textbf{Scribes}}: {
    Jisung Lim,
    \textit{B.S. Candidate of Industrial Engineering
    in Yonsei University, South Korea.}
  }

  {\textbf{Disclaimer}}: {
    \textit{These notes have not been subjected to the
    usual scrutiny reserved for formal publications.  They may be distributed
    outside this class only with the permission of the Instructor.}
  }
  \vspace*{4mm}
}
%
% Convention for citations is authors' initials followed by the year.
% For example, to cite a paper by Leighton and Maggs you would type
% \cite{LM89}, and to cite a paper by Strassen you would type \cite{S69}.
% (To avoid bibliography problems, for now we redefine the \cite command.)
% Also commands that create a suitable format for the reference list.
%\renewcommand{\cite}[1]{[#1]}
% \def\beginrefs{\begin{list}%
%         {[\arabic{equation}]}{\usecounter{equation}
%          \setlength{\leftmargin}{2.0truecm}\setlength{\labelsep}{0.4truecm}%
%          \setlength{\labelwidth}{1.6truecm}}}
% \def\endrefs{\end{list}}
% \def\bibentry#1{\item[\hbox{[#1]}]}

%Use this command for a figure; it puts a figure in wherever you want it.
%usage: \fig{NUMBER}{SPACE-IN-INCHES}{CAPTION}
\newcommand{\fig}[3]{
			\vspace{#2}
			\begin{center}
			Figure \thelecnum.#1:~#3
			\end{center}
	}
% Use these for theorems, lemmas, proofs, etc.

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\AtEndEnvironment{definition}{\qed}%
\newtheorem{theorem}{Theorem}[section]
\AtEndEnvironment{theorem}{\qed}%
\newtheorem{corollary}[theorem]{Corollary}
\AtEndEnvironment{corollary}{\qed}%
\newtheorem{lemma}[theorem]{Lemma}
\AtEndEnvironment{lemma}{\qed}%
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{claim}[theorem]{Claim}


\theoremstyle{remark}
\newtheorem{properties}[theorem]{Properties}
%\newtheorem{example}[theorem]{Example}
%\AtEndEnvironment{example}{\hfill\ensuremath{\Diamond}}%

\theoremstyle{remark}
\newtheorem{innerexample}[theorem]{Example}

\makeatletter
\patchcmd{\endinnerexample}{\endtrivlist}{\endlist}{}{}
\newenvironment{example}
 {\patchcmd{\@thm}{\trivlist}{\list{}{\leftmargin=3em \rightmargin=3em}}{}{}%
  \vspace*{10\p@}
  \innerexample\pushQED{\hfill\ensuremath{\Diamond}}}
 {\popQED\endinnerexample}
\makeatother


\newenvironment{prf}{{\bf Proof:}}{\hfill\rule{2mm}{2mm}}
\newenvironment{sol}{{\bf Solution:}}{\hfill\rule{2mm}{2mm}}
\newenvironment{skt}{{\bf Sketch:}}

% **** IF YOU WANT TO DEFINE ADDITIONAL MACROS FOR YOURSELF, PUT THEM HERE:

\newcommand\E{\mathbb{E}}

\begin{document}
%FILL IN THE RIGHT INFO.
%\lecture{**LECTURE-NUMBER**}{**DATE**}{**LECTURER**}{**SCRIBE**}
\lecture{5}{R.V. Transformation and MGF}{Jae Guk, Kim}{Jisung Lim}
%\footnotetext{These notes are partially based on those of Nigel Mansell.}

% **** YOUR NOTES GO HERE:x
\justify
\section{Random Variable Transformation}
We discussed about the distributional approach to the transformation of random
variables. Now, we shall discuss the calculus-based approach. First, we will deal
with an univariate transformation and then extend the concept to a multivariate
transformation.

\subsection{Univariate Transformation}
First of all, recall the basic calculus ``Integration of Substitution'',
given by
\begin{equation}
  \int_{\phi(a)}^{\phi(b)} f(x) \; dx
  = \int_{a}^{b} f(\phi(t)) \,|\phi^i(t)| \;dt
\end{equation}
where $\phi(t): [a,b] \rightarrow 1$. This formula is used to transform one
integral into another integral. Therefore, from this formula, we can find the
continuous probability distribution $P[Y \in A]$ of which integrand is a density:
\begin{equation}
  P[Y \in A] = \int_{\phi^{-1}(A)} f_X(x) \;dx
  = \int_A f_Y(\phi^{-1}(y))\,|(\phi^{-1})' (y)| \;dy
\end{equation}

\subsection{Multivariate Transformation}
Let us begin the discussion about the case of multivariate transformation in
some rigorous sense.

Let $G$ be an open set in $\mathbb{R}^n$ and let $\phi:G \rightarrow \mathbb{R}^n$
be continuously differentiable. Suppose $\phi$ is injective on $G$ and its
Jacobian never vanishes then

\begin{equation}
  \int_{\phi(G)} f(y) \;dy = \int_{G} f(\phi(x)) \, ||J_{\phi}(x)||\;dx
\end{equation}
where
\begin{equation}
  J_\phi (x) =
    \begin{bmatrix}
      \frac{\partial \phi_1}{\partial x_1} & \cdots & \frac{\partial \phi_1}{\partial x_n} \\
      \vdots & \ddots & \vdots \\
      \frac{\partial \phi_n}{\partial x_1} & \cdots & \frac{\partial \phi_n}{\partial x_n}
    \end{bmatrix}
    .
\end{equation}

\subsection{Bivariate transformation}
A specific example is given by the $\mathbb{R}^2 \rightarrow \mathbb{R}^2$ transformation,
which is called bivariate transformation.

Let $X$ be a random vector and $\phi$ be a transformation from $\mathbb{R}^n \rightarrow \mathbb{R}^n$
we want to find the distribution of $Y=\phi(X)$. Suppose $\phi$ is good enough
to satisfy any regularity needed to apply the theorem.
Note that, from a random vector $Y = (Y_1, Y_2)$, given by
\begin{equation}
  \begin{split}
    Y_1 &= \phi_1(X_1, X_2) \\
    Y_2 &= \phi_2(X_1, X_2),
  \end{split}
\end{equation}
we can find $\phi^{-1}$ such that
\begin{equation}
  \begin{split}
    X_1 &= \phi^{-1}_1 (Y_1, Y_2) \\
    X_2 &= \phi^{-1}_2 (Y_1, Y_2).
  \end{split}
\end{equation}
Then, by the Change of Variables
\begin{equation}
  \begin{split}
    P[Y \in A]
    &= \iint_{\phi^{-1}(A)} f_X(x_1, x_2) \; dx_1 dx_2 \\
    &= \iint_{A} f_X(\phi^{-1}(y_1, y_2)) \, ||J|| \; dy_1 dy_2
  \end{split}
\end{equation}
where
\begin{equation}
  J(x) =
    \begin{bmatrix}
      \frac{\partial x_1}{\partial y_1} & \frac{\partial x_1}{\partial y_2} \\
      \frac{\partial x_2}{\partial y_1} & \frac{\partial x_2}{\partial y_2}
    \end{bmatrix}
\end{equation}

From this specific example, we can understand the following theorem of
$\mathbb{R}^n \rightarrow \mathbb{R}^n$ generalization.
\begin{theorem}
  Let $X = (x_1, x_2, \ldots, x_n)$ have joint distributions $f$. Let $\phi:
  \mathbb{R}^n \rightarrow \mathbb{R}^n$ be continuously differentiable and
  intjective with non-vaninsh Jacobian. Then $Y = \phi(x)$ has density:
  \begin{equation}
    f_Y(y) = \left\{
      \begin{array}{ll}
        f_X(\phi^{-1}(y)) \, ||(J_{\phi^{-1}}(y))||, &\quad y \in \phi(\mathbb{R}^n) \\
        0                                            &\quad \textrm{otherwise}
      \end{array}
      \right.
  \end{equation}
\end{theorem}

\begin{example}
  Let $X$ and $Y$ be i.i.d. normal R.V's with $\mu=0$ and $\sigma^2 = 1$.
  What is the joint distribution of $(U,V) = (X+Y, X-Y)$?\\
  \begin{skt}
    \begin{enumerate}
      \item Define $\phi:(U, V) \rightarrow (X, Y)$ and find $\phi^{-1}$
      \item Evaluate Jacobian $J_{\phi^{-1}}(U, V)$ and it's determinant $||J||$
      \item Use the theorem to find $f_{(U,V)} (u, v)$.
    \end{enumerate}
  \end{skt}
  \begin{sol}
    $\frac{1}{\sqrt{4\pi}} \exp{\{-u^2/4\}} \frac{1}{\sqrt{4\pi}} \exp{\{-v^2/4\}}$
  \end{sol}

\end{example}

\section{Moment Generating Function}
\begin{definition}
  Let $X$ be a random variable, then
  \begin{equation}
    M_X(t) = \left\{
    \begin{array}{ll}
      \sum_i e^{tx_i} f(x_i)                    \quad & \textrm{$x$: distrete}\\[1em]
      \int_{-\infty}^{\infty} e^{tx} f(x) \; dx  \quad & \textrm{$x$: continuous}
    \end{array}
    \right.
  \end{equation}
  when it exists and call it the \textit{moment generating function} as a
  function fo $t$.
\end{definition}
By the definition of mathematical expectation $\mathbb{E}[\cdot]$, MGF can be
denoted by
\begin{equation}
 M_X(t) = \mathbb{E}_X[e^{tX}]
\end{equation}
and by differentiating the function with respect to $t$, we obtain,
\begin{equation}
  \begin{split}
    M_X'(t)
    &= \frac{d}{dt} \mathbb{E}[e^{tX}]   \\
    &= \frac{d}{dt} \int_{-\infty}^{\infty} e^{tx} f(x) \; dx \\
    &= \int_{-\infty}^{\infty} \frac{d}{dt} e^{tx} f(x) \; dx \quad \textrm{(Not always commutable)}\\
    &= \mathbb{E}[\frac{d}{dt} (e^{tX})] \\
    &= \mathbb{E}[X e^{tX}]
  \end{split}
\end{equation}
and let take $t = 0$ then,
\begin{equation}
  M_X'(0) = \mathbb{E}[X]
\end{equation}
which is called the first moment. Similarly, the second derivative is given by
\begin{equation}
  \begin{split}
    M_X''(t)
    &= \frac{d}{dt} M_X'(t) \\
    &= \frac{d}{dt} \mathbb{E}[X e^{tX}] \\
    &= \frac{d}{dt} \int_{-\infty}^{\infty} xe^{tx} f(x) \; dx \\
    &= \int_{-\infty}^{\infty} \frac{d}{dt} xe^{tx} f(x) \; dx \quad \textrm{(Not always commutable)}\\
    &= \mathbb{E}[\frac{d}{dt} (Xe^{tX})] \\
    &= \mathbb{E}[X^2e^{tX}]
  \end{split}
\end{equation}
and when $t=0$, the second moment is given by $M_X''(0) = \mathbb{E}[X^2]$. In
general, the $k$th derivative is given by
\begin{equation}
  M_X^{(k)}(t) = \mathbb{E}[X^k{e^{tX}}]
\end{equation}
and take $t=0$, then
\begin{equation}
  M_X^{(k)}(0) = \mathbb{E}[X^k]
\end{equation}
which is called the $k$-th moment of random variable $X$.
\begin{example}
  Let $X$ be a random variable, the PDF of which is given by
  \begin{equation*}
    f_X(x) = \frac{1}{\Gamma(\alpha)\beta^{\alpha}} x^{\alpha-1}e^{-x/\beta}
    \quad \textrm{where} \quad 0 < x < \infty,\, \alpha>0,\, \beta>0
  \end{equation*}
  Find MGF of $X$. \\
  \begin{sol}
    \begin{equation*}
      \begin{split}
        M_X(t)
        &= \int_{-\infty}^{\infty} e^{tx} f_X(t) \;dx \\
        &= \int_{-\infty}^{\infty} e^{tx} \frac{1}{\Gamma(\alpha)\beta^{\alpha}} x^{\alpha-1}e^{-x/\beta} \;dx \\
        &= \int_{-\infty}^{\infty} e^{tx} \frac{1}{\Gamma(\alpha)\beta^{\alpha}} x^{\alpha-1}e^{-x/\beta} \;dx \\
        &= \frac{{(\beta/(1-t\beta))}^\alpha}{\beta^{\alpha}} \int_{-\infty}^{\infty} \frac{1}{\Gamma(\alpha){(\beta/(1-t\beta))}^\alpha} x^{\alpha-1} e^{-\frac{x}{\beta/(1-t\beta)}}  \;dx \\
        &= \frac{{(\beta/(1-t\beta))}^\alpha}{\beta^\alpha} \\
        &= {\left\{\frac{1}{1-t\beta}\right\}}^\alpha
      \end{split}
    \end{equation*}
  \end{sol}
\end{example}

\begin{properties}{\it MFG has following properties:}\\
  \begin{itemize}
    \item {\bf Uniqueness:}\\
          If two random variables have the same MGF, than they have the same distribution.
    \item {\bf Linear Transformation:}\\
          If $Y = aX + b$, then
          $$
          M_Y(t) = e^{bt}M_X(at).
          $$
    \item {\bf Independent sums:}\\
          For independent random variable, says $X$ and $Y$, with $M_X(t), M_Y(t)$,
          respectively, the MGF of $Z = X + Y$ is given by
          $$
          M_Z(t) = M_{X+Y}(t) = M_X(t)M_Y(t) = \iint e^{t(x+y)}f_X(x)f_Y(y) \;dxdy.
          $$
  \end{itemize}
\end{properties}


\printbibliography

% **** THIS ENDS THE EXAMPLES. DON'T DELETE THE FOLLOWING LINE:

\end{document}
